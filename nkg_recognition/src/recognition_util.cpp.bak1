#include "nkg_recognition/recognition_util.h"

#include <pcl_conversions/pcl_conversions.h>
#include <pcl/filters/voxel_grid.h>
#include <pcl/filters/extract_indices.h>
#include <pcl/segmentation/sac_segmentation.h>
#include <pcl/segmentation/extract_clusters.h>

#include "geometric_shapes/shapes.h"
#include "geometric_shapes/shape_messages.h"
#include "geometric_shapes/shape_operations.h"
#include "geometric_shapes/mesh_operations.h"
#include "moveit_msgs/PlanningScene.h"

#include <fstream>
#include <iostream>
#include <ros/package.h>
#include <algorithm>
#include <tf2_eigen/tf2_eigen.h>


#define BASE_LINK "dobot_m1_base_link"
#define WEBCAM_FRAME "webcam_frame"

namespace recognition_util
{
RecognitionUtil::RecognitionUtil(){
	configParam();
	_xyzrgb_ptr = boost::make_shared<pcl::PointCloud<pcl::PointXYZRGB> >();
	_table_ptr = boost::make_shared<pcl::PointCloud<pcl::PointXYZRGB> >();
	_buffer.reset(new tf2_ros::Buffer(ros::Duration(10.0)));
	_listener.reset(new tf2_ros::TransformListener(*_buffer));
#if DEBUG
	_draw_pts.header.frame_id = BASE_LINK;
	_draw_pts.ns = "table";
	_draw_pts.action = visualization_msgs::Marker::ADD;
	_draw_pts.type = visualization_msgs::Marker::POINTS;
	_draw_pts.id = 0;
	_draw_pts.scale.x = 0.1;
	_draw_pts.scale.y = 0.1;
	_draw_pts.color.g = 1.0;
	_draw_pts.color.a = 1.0;
#endif
}

RecognitionUtil::~RecognitionUtil(){

}

void RecognitionUtil::start(){
	ros::NodeHandle n, _n("~");
	std::string topic;
	if (!_n.getParam("bb_topic", topic)){ROS_ERROR("No bb_topic!"); return;};
	_bb_sub = n.subscribe(topic, 1, &RecognitionUtil::bbCB, this);

	if (!_n.getParam("rgbd_topic", topic)){ROS_ERROR("No rgbd_topic!"); return;};
	_rgbd_sub = n.subscribe(topic, 1, &RecognitionUtil::rgbdCB, this);
	_obj_pub = n.advertise<moveit_msgs::PlanningScene>("recognizedScene", 1);
	_table_srv = n.advertiseService("get_table", &RecognitionUtil::getTable, this);
#if DEBUG
	_obj_pcl = n.advertise<sensor_msgs::PointCloud2>("clusterPCL",1);
	_table_pcl = n.advertise<sensor_msgs::PointCloud2>("tablePCL",1);
	_marker_pub = n.advertise<visualization_msgs::Marker>("visualization_marker", 5);
#endif
}

void RecognitionUtil::configParam(){
	ros::NodeHandle _n("~");
	_n.param("throttleRGBD", _throttle_rgbd, 5);
	_n.param("throttleBB", _throttle_bb, 5);
	_n.param("threshold", _threshold, 0.25);
	if (!_n.getParam("fx",_fx)){ROS_ERROR("No fx!"); return;};
	if (!_n.getParam("fy",_fy)){ROS_ERROR("No fy!"); return;};
	if (!_n.getParam("ppx",_ppx)){ROS_ERROR("No ppx!"); return;};
	if (!_n.getParam("ppy",_ppy)){ROS_ERROR("No ppy!"); return;};
	std::string line;
	std::ifstream file (ros::package::getPath("nkg_recognition")+"/config/names.txt");
	if (file.is_open()){
		while ( getline (file,line) ){
			std::stringstream ss(line);
			Instance instance;
			getline(ss,instance.name,',');
			if(getline(ss,line,','))
				instance.width = std::stof(line);
			if(getline(ss,line,','))
				instance.height = std::stof(line);
			if(getline(ss,line,','))
				instance.depth = std::stof(line);			
			_instances.push_back(instance);
		}
		file.close();
	}
	else
		ROS_ERROR("Unable to read Names!");
	ROS_INFO("Total %lu Classes.", _instances.size());
}

void RecognitionUtil::bbCB(const std_msgs::Float32MultiArrayConstPtr& msg){
	static int count = 0;
	if (++count < _throttle_bb)
		return;
	else
		count = 0;
	
	ROS_INFO("Start generating cuboids!");
	
	// protect _cuboids
	_mutex.lock();

	// carefully update cuboids, for we need to store information for future
	updateCuboids();

	BBox box;
	for (int i=0; i < msg->layout.dim[0].size; ++i){
		box.prob 	= msg->data[6*i+5];
		box.height 	= msg->data[6*i+4];
		box.width 	= msg->data[6*i+3];
		box.center.y= msg->data[6*i+2] + box.height/2;
		box.center.x= msg->data[6*i+1] + box.width/2;
		box.classId = static_cast<int>(msg->data[6*i]);
		generateCuboids(box);
	}
	_mutex.unlock();
}

void RecognitionUtil::updateCuboids(){
	// TODO
}

void RecognitionUtil::generateCuboids(const BBox& box){
	float camDW = _instances[box.classId].width  * _fx / box.width;
	float camDH = _instances[box.classId].height * _fy / box.height;

	// camDW and camDW should be close
	float diff = 0.2;
	if (fabs(camDW - camDH) > diff)
		ROS_WARN("camDW and camDH differs more than %f(m)", diff);

	float camD = sqrt(camDW * camDH);
	float camX = camD * (box.center.x-_ppx) / _fx, camY = camD * (box.center.y-_ppy) / _fy;

	// transform to BASE_LINK
	geometry_msgs::TransformStamped toWorld;
	try{
		toWorld = _buffer->lookupTransform(BASE_LINK, WEBCAM_FRAME, ros::Time(0));
	}
	catch (tf2::TransformException &ex) {
		ROS_WARN("%s",ex.what());
		return;
	}

	// generate cuboid
	Cuboid cuboid;
	cuboid.width  = _instances[box.classId].width;
	cuboid.height = _instances[box.classId].height;
	cuboid.depth  = _instances[box.classId].depth;

	Eigen::Vector3d cam(camX,camY,camD+cuboid.depth/2), world;
	tf2::doTransform(cam, world, toWorld);
	cuboid.center.x = world(0);
	cuboid.center.y = world(1);
	cuboid.center.z = world(2);
}

void RecognitionUtil::rgbdCB(const sensor_msgs::PointCloud2ConstPtr& msg){
	// time triggered
	static ros::WallTime record_t = ros::WallTime::now();
	static int count = 0;
	if (++count < _throttle_rgbd && (ros::WallTime::now()-record_t).toSec() < 0.1)
		return;
	else{
		count = 0;
		record_t = ros::WallTime::now();
	}

	pcl::PCLPointCloud2 *cloud = new pcl::PCLPointCloud2, *temp = new pcl::PCLPointCloud2;
	pcl::PCLPointCloud2ConstPtr cloud_ptr(cloud);
	pcl::PCLPointCloud2Ptr temp_ptr(temp);

	// Transform to pcl cloud
	pcl_conversions::toPCL(*msg, *cloud);

	// Voxel filter	
	pcl::VoxelGrid<pcl::PCLPointCloud2> vg;
	vg.setInputCloud(cloud_ptr);
	vg.setLeafSize (0.01f, 0.01f, 0.01f);
	vg.filter (*temp_ptr);

	// Transform to pcl::PointCloud<pcl::PointXYZRGB>
	pcl::fromPCLPointCloud2(*temp_ptr, *_xyzrgb_ptr);

	if (pclCluster()){
#if DEBUG
//		ROS_INFO("Get %lu clusters.", _clusters.size());
#endif
		// mutex with bbCB to protect _cuboids
		_mutex.lock();
		int paired = matchInstance();
		if(paired){
#if DEBUG
			ROS_INFO("Pair %d cuboids.", paired);
#endif
			tuneAndConstruct();
			_mutex.unlock();
			pubObjInfo();
		}
		else
			_mutex.unlock();
	}
	else
		ROS_WARN("No clusters!");
}

bool RecognitionUtil::pclCluster(){
	_clusters.clear();
	// Create the segmentation object for the planar model
	pcl::SACSegmentation<pcl::PointXYZRGB> seg;
	pcl::PointIndices::Ptr inliers (new pcl::PointIndices);
	pcl::ModelCoefficients::Ptr coefficients (new pcl::ModelCoefficients);
	seg.setOptimizeCoefficients (true);
	seg.setModelType (pcl::SACMODEL_PLANE);
	seg.setMethodType (pcl::SAC_RANSAC);
	seg.setMaxIterations (100);
	seg.setDistanceThreshold (0.02);

    // Segment the largest planar component from the input cloud
	seg.setInputCloud (_xyzrgb_ptr);
	seg.segment (*inliers, *coefficients);
	if (inliers->indices.empty())
		ROS_WARN("Could not estimate a planar model for the given dataset.");
	else{
	    // Remove the planar inliers from the input cloud
		pcl::PointCloud<pcl::PointXYZRGB>::Ptr temp_ptr(new pcl::PointCloud<pcl::PointXYZRGB>);
		pcl::ExtractIndices<pcl::PointXYZRGB> extract;
		extract.setInputCloud (_xyzrgb_ptr);
		extract.setIndices (inliers);
		extract.setNegative (false);
		extract.filter (*_table_ptr);
		updateTable();
		extract.setNegative (true);
		extract.filter (*temp_ptr);
		// Renew _xyxrgb_ptr
		*_xyzrgb_ptr = *temp_ptr;
	}	

	// Create the KdTree object for the search method of the extraction
	pcl::search::KdTree<pcl::PointXYZRGB>::Ptr tree(new pcl::search::KdTree<pcl::PointXYZRGB>);
	tree->setInputCloud(_xyzrgb_ptr);

	std::vector<pcl::PointIndices> cluster_indices;
	pcl::EuclideanClusterExtraction<pcl::PointXYZRGB> ec;
	ec.setClusterTolerance (0.02); // 2cm
	ec.setMinClusterSize (100);
	ec.setMaxClusterSize (25000);
	ec.setSearchMethod (tree);
	ec.setInputCloud(_xyzrgb_ptr);
	ec.extract (cluster_indices);

	if (cluster_indices.empty())
		return false;
	else{
		// Construct _clusters
		for (std::vector<pcl::PointIndices>::const_iterator it = cluster_indices.begin (); it != cluster_indices.end (); ++it)
			_clusters.push_back(Cluster(it->indices));
#if DEBUG
		pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud_cluster(new pcl::PointCloud<pcl::PointXYZRGB>);
		for (std::vector<pcl::PointIndices>::const_iterator it = cluster_indices.begin (); it != cluster_indices.end (); ++it){
			for (std::vector<int>::const_iterator pit = it->indices.begin (); pit != it->indices.end (); ++pit)
				cloud_cluster->points.push_back(_xyzrgb_ptr->points[*pit]);
		}
		cloud_cluster->header.frame_id = BASE_LINK;
		cloud_cluster->width = cloud_cluster->points.size();
		cloud_cluster->height = 1;
		cloud_cluster->is_dense = true;
		sensor_msgs::PointCloud2 obj_output, table_output;
		pcl::toROSMsg(*cloud_cluster, obj_output);
		_obj_pcl.publish(obj_output);
		// TODO frame transformation, w.r.t BASE_LINK / MAP ?
		_table_ptr->header.frame_id = BASE_LINK;
		pcl::toROSMsg(*_table_ptr, table_output);
		_table_pcl.publish(table_output);
#endif
		return true;
	}
}

int RecognitionUtil::matchInstance(){
	int matched = 0;
	for (int i=0; i<_cuboids.size() ; ++i){
		for (int j=0; j<_clusters.size(); ++j){
			if (isInCuboid(_cuboids[i], _clusters[j])){
				if (_clusters[j].getPairedIdx() != -1){
					// TODO split
				}
				else{
					_clusters[j].setPairedIdx(i);
					_cuboids[i].addCluster(j);
				}
			}
		}
		if (!_cuboids[i].cluster_list.empty())
			++matched;
	}
	return matched;
}

bool RecognitionUtil::isInCuboid(const Cuboid& cuboid, const Cluster& cluster){
	std::vector<int> indices = cluster.getIndices();
	int num = 0;
	for (int i=0; i<indices.size(); ++i){
		if (isInCuboid(cuboid, _xyzrgb_ptr->points[i]))
			++num;
	}
	float ratio = (float)num/indices.size();
	if ( ratio > _threshold)
		return true;
	else{
		ROS_INFO("Only %.2f%% of cluster in cuboid.", 100*ratio);
		return false;
	}
}

bool RecognitionUtil::isInCuboid(const Cuboid& cuboid, const pcl::PointXYZRGB& pt){
	if (fabs(pt.x-cuboid.center.x) <= cuboid.width && fabs(pt.y-cuboid.center.y) <= cuboid.depth && fabs(pt.z-cuboid.center.z) <= cuboid.height)
		return true;
	else
		return false;
}

void RecognitionUtil::tuneAndConstruct(){
	int iter, num;
	float update_thres = 0.01, errx, erry, gain = 0.2, updatex, updatey;
	// Fine tune for each cuboid 
	for (int i=0; i<_cuboids.size(); ++i){
		iter = 10;
		while(iter > 0 && fabs(updatex) + fabs(updatey) > update_thres){	// 1-norm
			errx = erry = 0.0;
			updatex = updatey = 0.0;
			num = 0;
			for (int j=0; j<_cuboids[i].cluster_list.size(); ++j){
				for (int k=0; k<_clusters[_cuboids[i].cluster_list[j]].getIndices().size(); ++k){
					if (!isInCuboid(_cuboids[i], _xyzrgb_ptr->points[k])){
						errx += _xyzrgb_ptr->points[k].x - _cuboids[i].center.x;
						erry += _xyzrgb_ptr->points[k].y - _cuboids[i].center.y;
						++num;
					}
				}
			}
			// Update center of cuboid by average error
			updatex = gain * errx/num;
			updatey = gain * erry/num;
			_cuboids[i].center.x += updatex;
			_cuboids[i].center.y += updatey;
			--iter;
		}
	}

	// Construct _obj_list
	_obj_list.clear();
	moveit_msgs::CollisionObject obj;
	obj.header.frame_id = BASE_LINK;
	geometry_msgs::Pose pose;
	pose.orientation.w = 1.0;
	// Size of primitive
	shape_msgs::SolidPrimitive primitive;
	primitive.type = primitive.BOX;
	primitive.dimensions.resize(3);
	obj.primitives.resize(1);
	obj.primitive_poses.resize(1);
	obj.operation = obj.ADD;

	for (int i=0; i<_cuboids.size(); ++i){
		if (!_cuboids[i].cluster_list.empty()){
			pose.position.x = _cuboids[i].center.x;
			pose.position.y = _cuboids[i].center.y;
			pose.position.z = _cuboids[i].center.z;
			primitive.dimensions[0] = _cuboids[i].width;
			primitive.dimensions[1] = _cuboids[i].depth;
			primitive.dimensions[2] = _cuboids[i].height;
			obj.primitives[0] = primitive;
			obj.primitive_poses[0] = pose;
			_obj_list.push_back(obj);
		}
	}
	ROS_INFO("Registrate %lu instances.", _obj_list.size());
}

void RecognitionUtil::pubObjInfo(){
	moveit_msgs::PlanningScene ps;
	ps.world.collision_objects.assign(_obj_list.begin(), _obj_list.end());
	ps.is_diff = false;
	_obj_pub.publish(ps);
}

void RecognitionUtil::updateTable(){
	std::vector<cv::Point2f> pts;
	pts.resize(_table_ptr->points.size());
	cv::Point2f temp;
	float depth=0.0;
	for (int i=0; i<pts.size(); ++i){
		temp.x = _table_ptr->points[i].x;
		temp.y = _table_ptr->points[i].y;
		depth += _table_ptr->points[i].z;
		pts[i] = temp;
	}
	cv::RotatedRect table = cv::minAreaRect(pts);
	_table.center.x = table.center.x;
	_table.center.y = table.center.y;
	_table.width = table.size.width;
	_table.height = table.size.height;
	_table.depth = depth/pts.size();
	_table.angle = table.angle;
#if DEBUG
	geometry_msgs::Point pt;
	_draw_pts.points.clear();
	pt.z = _table.depth;
	cv::Point2f vertices[4];
	table.points(vertices);
	for (int i=0; i<4; ++i){
		pt.x = vertices[i].x;
		pt.y = vertices[i].y;
		_draw_pts.points.push_back(pt);
	}
	_marker_pub.publish(_draw_pts);
#endif
}

bool RecognitionUtil::getTable(nkg_demo_msgs::Table::Request &req,nkg_demo_msgs::Table::Response &res){
	res.table.resize(6);
	res.table[0] = _table.center.x;
	res.table[1] = _table.center.y;
	res.table[2] = _table.width;
	res.table[3] = _table.height;
	res.table[4] = _table.depth;
	res.table[5] = _table.angle;

	// according to openCV, angle is within (-90,0] (degree)
	float angle_thres = 90.0, iou_thres = 0.3;
	if (_table.angle > -angle_thres || _table.angle+90 < angle_thres){	// consider aligned
		res.ready = true;
		if (req.cleaned_table[2] == 0 || req.cleaned_table[3] == 0)
			res.update = true;
		else{
			Table cleaned_table(req.cleaned_table);
			res.update = (_table.iou(cleaned_table) < iou_thres);
		}
	}
	else{
		res.ready = false;
		res.update = false;
	}
	return true;
}

}	// namespace recognition_util
